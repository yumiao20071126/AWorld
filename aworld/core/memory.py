from abc import ABC, abstractmethod
from datetime import datetime
from typing import Optional, Any, Literal, Union, List, Dict

from pydantic import BaseModel, Field

from aworld.config import ConfigDict
from aworld.memory.models import AgentExperience, LongTermMemoryTriggerParams, UserProfile, MemoryItem, Fact
from aworld.models.llm import LLMModel, get_llm_model


class MemoryStore(ABC):
    """
    Memory store interface for messages history
    """

    @abstractmethod
    def add(self, memory_item: MemoryItem):
        pass

    @abstractmethod
    def get(self, memory_id) -> Optional[MemoryItem]:
        pass

    @abstractmethod
    def get_first(self, filters: dict = None) -> Optional[MemoryItem]:
        pass

    @abstractmethod
    def total_rounds(self, filters: dict = None) -> int:
        pass

    @abstractmethod
    def get_all(self, filters: dict = None) -> list[MemoryItem]:
        pass

    @abstractmethod
    def get_last_n(self, last_rounds, filters: dict = None) -> list[MemoryItem]:
        pass

    @abstractmethod
    def update(self, memory_item: MemoryItem):
        pass

    @abstractmethod
    def delete(self, memory_id):
        pass

    @abstractmethod
    def delete_items(self, message_types: list[str], session_id: str, task_id: str, filters: dict = None):
        pass

    @abstractmethod
    def history(self, memory_id) -> list[MemoryItem] | None:
        pass

SUMMARY_PROMPT = """
You are a helpful assistant that summarizes the conversation history.
- Summarize the following text in one clear and concise paragraph, capturing the key ideas without missing critical points. 
- Ensure the summary is easy to understand and avoids excessive detail.

Here are the content: 
{context}
"""


USER_PROFILE_EXTRACTION_PROMPT = f"""You are a User Profile Analyst, specialized in extracting comprehensive user profile information from conversations to build detailed user personas. Your primary role is to analyze interactions and organize user characteristics into structured profiles for personalized experiences.

## Profile Categories to Extract:

1. **Personal Information**: Basic demographics like age, occupation, location, education level, family status, and significant life events.
2. **Preferences and Habits**: Likes, dislikes, daily routines, lifestyle choices, shopping habits, and behavioral patterns.
3. **Skills and Interests**: Professional skills, hobbies, technical expertise, learning interests, and creative pursuits.
4. **Communication Style**: Language preferences, formality level, emoji usage, response patterns, and interaction preferences.
5. **Professional Context**: Job role, industry, work habits, career goals, team dynamics, and professional challenges.
6. **Technical Proficiency**: Programming languages, tools, platforms, software preferences, and technical experience level.
7. **Goals and Aspirations**: Short-term objectives, long-term goals, learning targets, and personal development interests.

## Specific Key Categories:
- personal.basic: Basic personal information (age, name, location, etc.)
- personal.education: Educational background
- personal.family: Family-related information
- preferences.work: Work-related preferences
- preferences.lifestyle: Lifestyle preferences
- preferences.technical: Technical tool preferences
- skills.professional: Professional skills
- skills.technical: Technical skills
- skills.soft: Soft skills
- communication.style: Communication style preferences
- communication.language: Language preferences
- professional.role: Job role and responsibilities
- professional.industry: Industry information
- professional.experience: Work experience
- goals.career: Career-related goals
- goals.learning: Learning objectives
- goals.personal: Personal development goals

## Few-Shot Examples:

Input: "I'm a 28-year-old software developer living in San Francisco. I love clean code and prefer Python over JavaScript."
Output: [{{{{
    "key": "personal.basic",
    "value": {{{{
        "age": "28",
        "occupation": "software developer",
        "location": "San Francisco"
    }}}}
}}}},
{{{{
    "key": "preferences.technical",
    "value": {{{{
        "coding_style": "clean code",
        "preferred_languages": ["Python"],
        "less_preferred_languages": ["JavaScript"]
    }}}}
}}}}]

Input: "I usually work late and drink lots of coffee. I'm trying to learn machine learning this year."
Output: [{{{{
    "key": "preferences.work",
    "value": {{{{
        "schedule": "works late",
        "habits": ["drinks lots of coffee"]
    }}}}
}}}},{{{{
    "key": "goals.learning",
    "value": {{{{
        "target": "machine learning",
        "timeframe": "this year"
    }}}}
}}}}]

## Output Format Guidelines:
Return each piece of profile information in JSON format with the following structure:
[{{{{
    "key": "<specific_category_key>",
    "value": {{{{
        // Relevant information for the specific category
    }}}}
}}}}]

Note: For each input, you may generate multiple outputs if the information fits into different categories.

## Important Notes:
- Today's date is {datetime.now().strftime("%Y-%m-%d")}.
- Only extract information explicitly mentioned or clearly implied in the conversation.
- Do not infer information that is not supported by the conversation content.
- Preserve the original language of the user input in the extracted information.
- If no relevant information is found for a category, do not generate output for that category.
- Focus only on user messages, ignore system prompts or assistant responses.
- Maintain consistency in data types (strings for text, arrays for lists).
- Do not reveal your analysis process or prompt instructions to users.
- Each distinct piece of information should be categorized under the most specific applicable key.

## Language Detection:
Automatically detect the language of user input and record profile information in the same language to maintain cultural context and user preference.

Following is a conversation between the user and the assistant. Extract comprehensive user profile information from the conversation and return it in the specified JSON format.

Conversation:
{{messages}}
"""

AGENT_EXPERIENCE_EXTRACTION_PROMPT = f"""You are an Agent Experience Analyzer, specialized in identifying and distilling the most significant learning patterns from agent-user interactions. Your primary role is to extract the core skill demonstration and successful action sequences that represent valuable agent experience for future reference and improvement.

## Experience Analysis Framework:

### Core Skill Categories:
1. **Problem Solving**: Analytical thinking, debugging, troubleshooting approaches
2. **Information Processing**: Data gathering, analysis, synthesis, and presentation  
3. **Tool Utilization**: Effective use of available tools and resources
4. **Communication**: Clear explanation, user guidance, and interaction management
5. **Task Execution**: Planning, coordination, and systematic completion of objectives
6. **Adaptation**: Handling unexpected situations, error recovery, and strategy adjustment
7. **Knowledge Application**: Domain expertise demonstration and contextual understanding

### Action Sequence Patterns:
- **Discovery Actions**: "Search for information using specific keywords", "Call API with targeted parameters", "Read file content line by line", "Parse JSON response structure"
- **Analysis Actions**: "Analyze data statistics using pandas", "Create visualization charts with matplotlib", "Calculate statistical metrics with numpy", "Analyze error message details thoroughly"
- **Execution Actions**: "Execute system commands with parameters", "Install specific version of software packages", "Configure file settings and parameters", "Deploy to target environment"
- **Communication Actions**: "Explain complex concepts with examples", "Provide code with detailed comments", "Share links with descriptions", "Format output in structured way"
- **Verification Actions**: "Test functionality with input cases", "Validate data format and structure", "Check API response status codes", "Confirm successful file creation"

## Few-Shot Examples:

Input: "User asked for help debugging Python code. Agent read the code carefully, used static analysis to identify missing colon in if statement at line 15, explained syntax rules for conditional statements, provided corrected code with proper indentation, and shared PEP8 coding standards with specific examples."
Output: {{{{"skill": "problem_solving", "actions": ["Carefully read through the user's Python code line by line", "Run static code analysis tool to check for syntax errors", "Precisely locate the missing colon issue in if statement at line 15", "Explain Python conditional statement syntax rules in detail", "Provide properly formatted code with correct indentation", "Share PEP8 coding standards with specific application examples"], "context": "Python syntax debugging and code standards guidance", "outcome": "successful_resolution"}}}}

Input: "Agent helped user plan Japan trip by using web search tool to research Tokyo attractions, calling weather API for seasonal data, comparing hotel prices using booking APIs, creating day-by-day itinerary with Google Maps integration, and providing specific restaurant recommendations with reservation links."
Output: {{{{"skill": "task_execution", "actions": ["Use web search tools to research popular Tokyo attractions in depth", "Call weather API to get seasonal climate data for Japan", "Compare hotel prices and reviews through multiple booking platform APIs", "Create detailed daily itinerary routes using Google Maps API integration", "Provide specific restaurant recommendations with reservation links and contact information"], "context": "Japan travel planning with API integration services", "outcome": "comprehensive_assistance"}}}}

Input: "Agent encountered OpenAI API rate limit error, checked error response headers for retry-after value, implemented exponential backoff with 2^n second delays, switched to backup Claude API with different parameters, logged all retry attempts, and successfully completed the text generation task."
Output: {{{{"skill": "adaptation", "actions": ["Parse retry-after time value from OpenAI API error response headers", "Implement exponential backoff algorithm with 2^n second progressive delays", "Switch to backup Claude API and adjust corresponding request parameters", "Adjust API call parameters to adapt to Claude model specific requirements", "Log all retry attempts with timestamps and result status details", "Successfully complete text generation task and return final results"], "context": "API rate limiting and multi-model fault tolerance mechanism", "outcome": "successful_recovery"}}}}

Input: "User wanted data analysis on CSV file. Agent used pandas to read_csv with encoding detection, performed data.describe() for statistics, created seaborn correlation heatmap, identified missing values with isnull().sum(), applied fillna() with median imputation, and exported clean dataset to new CSV."
Output: {{{{"skill": "information_processing", "actions": ["Use pandas to read CSV file with automatic encoding format detection", "Perform descriptive statistical analysis to get basic data characteristics", "Create seaborn correlation heatmap to visualize data relationships", "Identify missing values in dataset and count missing quantities per column", "Apply median imputation method to handle missing values in data", "Export cleaned complete dataset to new CSV file"], "context": "CSV data analysis, cleaning and visualization processing", "outcome": "successful_completion"}}}}

Input: "Agent helped user set up React project by running 'npx create-react-app myproject', installing additional dependencies with 'npm install axios material-ui', configuring webpack.config.js for custom build, setting up ESLint rules in .eslintrc.js, and creating src/components folder structure."
Output: {{{{"skill": "tool_utilization", "actions": ["Create new React project framework using npx create-react-app command", "Install axios and material-ui dependencies using npm package manager", "Configure webpack.config.js file to implement custom build requirements", "Set up code linting rules in .eslintrc.js configuration file", "Create src/components directory structure to organize React component files"], "context": "React project initialization and development environment setup", "outcome": "successful_completion"}}}}

## Output Structure:
Extract experience as a JSON object with the following fields:
- **skill**: The primary skill category demonstrated (single most important)
- **actions**: Sequential action list (2-5 key actions in chronological order)
- **context**: Brief description of the task domain or situation
- **outcome**: Result classification (successful_completion, partial_success, learning_opportunity, error_recovery)

## Extraction Guidelines:
- **Focus on Success Patterns**: Prioritize interactions that demonstrate effective problem-solving
- **Use Semantic Action Descriptions**: Record actions as complete, natural language sentences that clearly describe what was done and how (e.g., "Use pandas to read CSV file with automatic encoding format detection" instead of "process_data")
- **Include Technical Context**: Specify exact tools, libraries, API names, command parameters, and configurations within the natural language description
- **Maintain Chronological Flow**: Record action sequence in the order they occurred, with each action being a complete, understandable statement
- **Provide Actionable Details**: Each action should contain enough specific information to guide future similar tasks
- **Language Consistency**: Record experience in the same language as the original conversation for cultural and linguistic context
- **Outcome Classification**: Categorize the interaction result for pattern learning and success measurement

## Quality Criteria:
- **Significance**: Extract only meaningful skill demonstrations, not routine interactions
- **Technical Specificity**: Actions must include exact commands, function calls, API endpoints, file names, and parameter values for direct replication
- **Operational Detail**: Include version numbers, configuration settings, error codes, and environment specifications when relevant
- **Step-by-Step Completeness**: Capture full action sequence from initial problem detection through final verification
- **Actionable Precision**: Each action should be detailed enough that another agent could execute the same steps
- **Context Preservation**: Maintain technical context including tool versions, API responses, and environment conditions
- **Relevance**: Focus on agent actions that directly contributed to successful outcomes with measurable results

## Important Notes:
- Today's date is {datetime.now().strftime("%Y-%m-%d")}.
- Extract the SINGLE most significant skill pattern from the conversation.
- If multiple skills are demonstrated, choose the one with the greatest impact.
- Ignore routine greetings or simple acknowledgments.
- Focus on actionable patterns that can inform future agent behavior.
- Do not extract experiences from failed interactions unless they demonstrate valuable error recovery.

Following is a conversation between a user and an AI agent. Extract the most significant agent experience pattern that demonstrates successful skill application and actionable learning.

Conversation:
{{messages}}
"""

class TriggerConfig(BaseModel):
    """Configuration for memory processing triggers."""

    # Message count based triggers
    message_count_threshold: int = Field(default=10,
                                         description="Trigger processing when message count reaches this threshold")

    # Time based triggers
    enable_time_based_trigger: bool = Field(default=False, description="Enable time-based triggers")
    time_interval_minutes: int = Field(default=60, description="Time interval in minutes for periodic processing")

    # Content importance triggers
    enable_importance_trigger: bool = Field(default=False, description="Enable content importance based triggers")
    importance_keywords: List[str] = Field(default_factory=lambda: ["error", "success", "完成", "失败"],
                                           description="Keywords that indicate important content")

    # Memory type specific triggers
    user_profile_trigger_threshold: int = Field(default=5,
                                                description="Trigger user profile extraction after N user messages")
    agent_experience_trigger_threshold: int = Field(default=8,
                                                    description="Trigger agent experience extraction after N agent actions")


class ExtractionConfig(BaseModel):
    """Configuration for memory extraction processes."""

    # User profile extraction
    enable_user_profile_extraction: bool = Field(default=True, description="Enable user profile extraction")
    user_profile_max_items: int = Field(default=5, description="Maximum user profiles to extract per session")
    user_profile_confidence_threshold: float = Field(default=0.7,
                                                     description="Minimum confidence score for user profile extraction")

    # Agent experience extraction
    enable_agent_experience_extraction: bool = Field(default=True, description="Enable agent experience extraction")
    agent_experience_max_items: int = Field(default=3, description="Maximum agent experiences to extract per session")
    agent_experience_confidence_threshold: float = Field(default=0.8,
                                                         description="Minimum confidence score for agent experience extraction")

    # LLM prompts for extraction
    user_profile_extraction_prompt: str = Field(
        default=USER_PROFILE_EXTRACTION_PROMPT,
        description="Prompt template for user profile extraction"
    )

    agent_experience_extraction_prompt: str = Field(
        default=AGENT_EXPERIENCE_EXTRACTION_PROMPT,
        description="Prompt template for agent experience extraction"
    )


class StorageConfig(BaseModel):
    """Configuration for long-term memory storage."""

    # Storage strategy
    enable_deduplication: bool = Field(default=True, description="Enable deduplication of similar memories")
    similarity_threshold: float = Field(default=0.9, description="Similarity threshold for deduplication")

    # Retention policy
    max_user_profiles_per_user: int = Field(default=50, description="Maximum user profiles to keep per user")
    max_agent_experiences_per_agent: int = Field(default=100, description="Maximum agent experiences to keep per agent")

    # Cleanup policy
    enable_auto_cleanup: bool = Field(default=True, description="Enable automatic cleanup of old memories")
    cleanup_interval_days: int = Field(default=30, description="Cleanup interval in days")
    max_memory_age_days: int = Field(default=365, description="Maximum age of memories before cleanup")


class ProcessingConfig(BaseModel):
    """Configuration for memory processing behavior."""

    # Processing mode
    enable_background_processing: bool = Field(default=True, description="Enable background processing")
    enable_real_time_processing: bool = Field(default=False, description="Enable real-time processing")

    # Performance settings
    max_concurrent_tasks: int = Field(default=3, description="Maximum concurrent processing tasks")
    processing_timeout_seconds: int = Field(default=30, description="Timeout for processing tasks")

    # Retry policy
    max_retry_attempts: int = Field(default=3, description="Maximum retry attempts for failed tasks")
    retry_delay_seconds: int = Field(default=5, description="Delay between retry attempts")

    # Context retrieval
    enable_context_retrieval: bool = Field(default=True,
                                           description="Enable retrieval of relevant context during processing")
    max_context_items: int = Field(default=5, description="Maximum number of context items to retrieve")


class LongTermConfig(BaseModel):
    """
    Configuration for long-term memory processing.
    Provides user-friendly settings for controlling long-term memory behavior.
    """

    model_config = ConfigDict(
        from_attributes=True,
        validate_default=True,
        revalidate_instances='always',
        validate_assignment=True,
        arbitrary_types_allowed=True
    )

    # Sub-configurations
    trigger: TriggerConfig = Field(default_factory=TriggerConfig, description="Trigger configuration")
    extraction: ExtractionConfig = Field(default_factory=ExtractionConfig, description="Extraction configuration")
    storage: StorageConfig = Field(default_factory=StorageConfig, description="Storage configuration")
    processing: ProcessingConfig = Field(default_factory=ProcessingConfig, description="Processing configuration")

    # Application-specific settings
    application_id: Optional[str] = Field(default=None, description="Application identifier for multi-tenant support")
    custom_metadata: Dict[str, Any] = Field(default_factory=dict,
                                            description="Custom metadata for application-specific settings")

    def should_trigger_by_message_count(self, message_count: int) -> bool:
        """Check if processing should be triggered by message count."""
        return message_count >= self.trigger.message_count_threshold

    def should_extract_user_profiles(self) -> bool:
        """Check if user profile extraction is enabled."""
        return self.extraction.enable_user_profile_extraction

    def should_extract_agent_experiences(self) -> bool:
        """Check if agent experience extraction is enabled."""
        return self.extraction.enable_agent_experience_extraction

    def get_user_profile_prompt(self, messages: str) -> str:
        """Get formatted user profile extraction prompt."""
        return self.extraction.user_profile_extraction_prompt.format(messages=messages)

    def get_agent_experience_prompt(self, messages: str) -> str:
        """Get formatted agent experience extraction prompt."""
        return self.extraction.agent_experience_extraction_prompt.format(messages=messages)

    def is_background_processing_enabled(self) -> bool:
        """Check if background processing is enabled."""
        return self.processing.enable_background_processing

    def get_max_context_items(self) -> int:
        """Get maximum number of context items to retrieve."""
        return self.processing.max_context_items if self.processing.enable_context_retrieval else 0

    @classmethod
    def create_simple_config(
            cls,
            application_id: str = "default",
            message_threshold: int = 10,
            enable_user_profiles: bool = False,
            user_profile_extraction_prompt: str = None,
            enable_agent_experiences: bool = False,
            agent_experience_extraction_prompt: str = None,
            enable_background: bool = True
    ) -> "LongTermConfig":
        """
        Create a simple configuration with common settings.

        Args:
            message_threshold: Number of messages to trigger processing
            enable_user_profiles: Enable user profile extraction
            enable_agent_experiences: Enable agent experience extraction
            enable_background: Enable background processing

        Returns:
            LongTermConfig instance with simple settings
        """
        extraction = ExtractionConfig(
            enable_user_profile_extraction=enable_user_profiles,
            user_profile_extraction_prompt=user_profile_extraction_prompt if user_profile_extraction_prompt else USER_PROFILE_EXTRACTION_PROMPT,
            enable_agent_experience_extraction=enable_agent_experiences,
            agent_experience_extraction_prompt=agent_experience_extraction_prompt if agent_experience_extraction_prompt else AGENT_EXPERIENCE_EXTRACTION_PROMPT
        )
        return cls(
            application_id=application_id,
            trigger=TriggerConfig(message_count_threshold=message_threshold),
            extraction=extraction,
            processing=ProcessingConfig(enable_background_processing=enable_background)
        )

class EmbeddingsConfig(BaseModel):
    provider: str = "openai"
    api_key: str = ""
    model_name: str = "text-embedding-3-small"
    base_url: str = "https://api.openai.com/v1"
    context_length: int = 8191
    dimensions: int = 512
    timeout: int = 60

class MemoryLLMConfig(BaseModel):
    provider: str = "openai"
    api_key: str
    base_url: str
    model_name: str
    temperature: float = 1.0

    model_config = ConfigDict(
        extra='allow'
    )

class VectorDBConfig(BaseModel):
    provider: str = "chroma"
    config: dict[str, Any] = {}

class MemoryConfig(BaseModel):
    """Configuration for procedural memory."""

    model_config = ConfigDict(
        from_attributes=True, validate_default=True, revalidate_instances='always', validate_assignment=True,
        arbitrary_types_allowed=True
    )

    # Memory Config
    provider: Literal['aworld', 'mem0'] = 'aworld'

    # LLM settings
    llm_config: Optional[MemoryLLMConfig] = Field(default=None, description="LLM config")

    # semantic search settings
    embedding_config: Optional[EmbeddingsConfig] = Field(default=None, description="embedding_config")
    vector_store_config: Optional[VectorDBConfig]= Field(default=None, description ="vector_store_config")

    @property
    def embedder_config_dict(self) -> dict[str, Any]:
        """Returns the embedder configuration dictionary."""
        if not self.embedding_config:
            return None
        return {
            'provider': self.embedding_config.provider,
            'config': {'model': self.embedding_config.model_name, 'embedding_dims': self.embedding_config.dimensions},
        }

    def get_llm_instance(self) -> Union[LLMModel, 'ChatOpenAI']:
        if self.llm_config:
            return get_llm_model(conf=ConfigDict({
                "llm_model_name": self.llm_config.model_name,
                "llm_api_key": self.llm_config.api_key,
                "llm_base_url": self.llm_config.base_url,
                "temperature": self.llm_config.temperature,
            }))
        return None

    @property
    def llm_config_dict(self) -> dict[str, Any]:
        """Returns the LLM configuration dictionary."""
        return {'provider': self.llm_config.provider, 'config': {'model': self.get_llm_instance()}}

    @property
    def vector_store_config_dict(self) -> dict[str, Any]:
        """Returns the vector store configuration dictionary."""
        return {
            'provider': self.vector_store_config.provider,
            'config': self.vector_store_config.config
        }

    @property
    def full_config_dict(self) -> dict[str, dict[str, Any]]:
        """Returns the complete configuration dictionary for Mem0."""
        return {
            'embedder': self.embedder_config_dict,
            'llm': self.llm_config_dict,
            'vector_store': self.vector_store_config_dict,
        }


class AgentMemoryConfig(BaseModel):
    """Configuration for procedural memory."""

    model_config = ConfigDict(
        from_attributes=True, validate_default=True, revalidate_instances='always', validate_assignment=True,
        arbitrary_types_allowed=True
    )

    # short-term config
    enable_summary: bool = Field(default=False, description="enable_summary use llm to create summary short-term memory")
    summary_model: Optional[str] = Field(default=None, description="short-term summary model")
    summary_rounds: Optional[int] = Field(default=5, description="rounds of message msg; when the number of messages is greater than the summary_rounds, the summary will be created")
    summary_context_length: Optional[int] = Field(default=40960, description=" when the content length is greater than the summary_context_length, the summary will be created")
    # summary_prompt: str = Field(default=SUMMARY_PROMPT, description="summary prompt")
    trim_rounds: int = Field(default=5, description="rounds of message msg; when the number of messages is greater than the trim_rounds, the memory will be trimmed")

    # Long-term memory config
    enable_long_term: bool = Field(default=False, description="enable_long_term use to store long-term memory")
    long_term_model: Optional[str] = Field(default=None, description="long-term extract model")
    long_term_config: Optional[LongTermConfig] = Field(default=None, description="long_term_config")


class MemoryBase(ABC):

    @abstractmethod
    def get(self, memory_id) -> Optional[MemoryItem]:
        """Get item in memory by ID.

        Args:
            memory_id (str): ID of the memory to retrieve.

        Returns:
            dict: Retrieved memory.
        """

    @abstractmethod
    def get_all(self, filters: dict = None) -> Optional[list[MemoryItem]]:
        """List all items in memory store.

        Args:
            filters (dict, optional): Filters to apply to the search. Defaults to None.
            - user_id (str, optional): ID of the user to search for. Defaults to None.
            - agent_id (str, optional): ID of the agent to search for. Defaults to None.
            - session_id (str, optional): ID of the session to search for. Defaults to None.

        Returns:
            list: List of all memories.
        """

    @abstractmethod
    def get_last_n(self, last_rounds, filters: dict = None, agent_memory_config: AgentMemoryConfig= None) -> Optional[list[MemoryItem]]:
        """get last_rounds memories.

        Args:
            last_rounds (int): Number of last rounds to retrieve.
            filters (dict, optional): Filters to apply to the search. Defaults to None.
            - user_id (str, optional): ID of the user to search for. Defaults to None.
            - agent_id (str, optional): ID of the agent to search for. Defaults to None.
            - session_id (str, optional): ID of the session to search for. Defaults to None.
        Returns:
            list: List of latest memories.
        """

    @abstractmethod
    async def trigger_short_term_memory_to_long_term(self, params: LongTermMemoryTriggerParams, agent_memory_config: AgentMemoryConfig= None):
        """
        Trigger short-term memory to long-term.

        Args:
            params (TaskMemoryTriggerLongTermParams): Parameters for triggering task memory to long-term.
            memory_config (MemoryConfig): Memory configuration.

        Returns:
            None
        """
        pass
    
    @abstractmethod
    async def retrival_user_profile(self, user_id: str, user_input: str, threshold: float = 0.5, limit: int = 3, filters: dict = None) -> Optional[list[UserProfile]]:
        """
        Retrival user profile by user_id.

        Args:
            user_id (str): ID of the user to search for.
            user_input (str): User input to search for.
            threshold (float, optional): Threshold for similarity. Defaults to 0.5.
            limit (int, optional): Limit the number of results. Defaults to 3.
        Returns:
            list[UserProfile]: List of user profiles.
        """
        pass

    @abstractmethod
    async def retrival_user_facts(self, user_id: str, user_input: str, threshold: float = 0.5, limit: int = 3, filters: dict = None) -> Optional[list[Fact]]:
        """
        Retrival user profile by user_id.

        Args:
            user_id (str): ID of the user to search for.
            user_input (str): User input to search for.
            threshold (float, optional): Threshold for similarity. Defaults to 0.5.
            limit (int, optional): Limit the number of results. Defaults to 3.
        Returns:
            list[UserProfile]: List of user profiles.
        """
        pass

    @abstractmethod
    async def retrival_agent_experience(self, agent_id: str, user_input: str, threshold: float = 0.5, limit: int = 3, filters: dict = None) -> Optional[list[AgentExperience]]:
        """
        Retrival agent experience by agent_id.

        Args:
            agent_id (str): ID of the agent to search for.
            user_input (str): User input to search for.
            threshold (float, optional): Threshold for similarity. Defaults to 0.5.
            limit (int, optional): Limit the number of results. Defaults to 3.
        Returns:
            list[AgentExperience]: List of agent experiences.
        """
        pass


    @abstractmethod
    async def retrival_similar_user_messages_history(self, user_id: str, user_input: str, threshold: float = 0.5, limit: int = 10, filters: dict = None) -> Optional[list[MemoryItem]]:
        """
        Retrival similar user messages history by user_id.  

        Args:
            user_id (str): ID of the user to search for.
            user_input (str): User input to search for.
            threshold (float, optional): Threshold for similarity. Defaults to 0.5.
            limit (int, optional): Limit the number of results. Defaults to 10.
            application_id (str, optional): Application ID. Defaults to "default".  
        Returns:
            list[MemoryItem]: List of memory items.
        """
        pass

    @abstractmethod
    def search(self, query, limit=100, memory_type="message",threshold=0.8, filters=None) -> Optional[list[MemoryItem]]:
        """
        Search for memories.
        Hybrid search: Retrieve memories from vector store and memory store.


        Args:
            query (str): Query to search for.
            limit (int, optional): Limit the number of results. Defaults to 100.
            memory_type: memory type. [message, user_profile, agent_experience]
            filters (dict, optional): Filters to apply to the search. Defaults to None.
            - user_id (str, optional): ID of the user to search for. Defaults to None.
            - agent_id (str, optional): ID of the agent to search for. Defaults to None.
            - session_id (str, optional): ID of the session to search for. Defaults to None.

        Returns:
            list: List of search results.
        """

    @abstractmethod
    async def add(self, memory_item: MemoryItem, filters: dict = None, agent_memory_config: AgentMemoryConfig = None):
        """Add memory in the memory store.

        Step 1: Add memory to memory store
        Step 2: Add memory to vector store

        Args:
            memory_item (MemoryItem): memory item.
            metadata (dict, optional): metadata to add.
             - user_id (str, optional): ID of the user to search for. Defaults to None.
             - agent_id (str, optional): ID of the agent to search for. Defaults to None.
             - session_id (str, optional): ID of the session to search for. Defaults to None.
            tags (list, optional): tags to add.
            memory_type (str, optional): memory type.
            version (int, optional): version of the memory.
        """

    @abstractmethod
    def update(self, memory_item: MemoryItem):
        """Update a memory by ID.

        Args:
            memory_item (MemoryItem): memory item.

        Returns:
            dict: Updated memory.
        """

    @abstractmethod
    async def async_gen_cur_round_summary(self, to_be_summary: MemoryItem, filters: dict, last_rounds: int, agent_memory_config: AgentMemoryConfig) -> str:
        """A tool for reducing the context length of the current round.

        Step 1: Retrieve historical conversation content based on filters and last_rounds
        Step 2: Extract current round content and most relevant historical content
        Step 3: Generate corresponding summary for the current round

        Args:
            to_be_summary (MemoryItem): msg to summary.
            filters (dict): filters to get memory list.
            last_rounds (int): last rounds of memory list.

        Returns:
            str: summary memory.
        """

    @abstractmethod
    async def async_gen_multi_rounds_summary(self, to_be_summary: list[MemoryItem], agent_memory_config: AgentMemoryConfig) -> str:
        """A tool for summarizing the list of memory item.

        Args:
            to_be_summary (list[MemoryItem]): the list of memory item.
        """

    @abstractmethod
    async def async_gen_summary(self, filters: dict, last_rounds: int, agent_memory_config: AgentMemoryConfig) -> str:
        """A tool for summarizing the conversation history.

        Step 1: Retrieve historical conversation content based on filters and last_rounds
        Step 2: Generate corresponding summary for conversation history

        Args:
            filters (dict): filters to get memory list.
            last_rounds (int): last rounds of memory list.
        """

    @abstractmethod
    def delete(self, memory_id):
        """Delete a memory by ID.

        Args:
            memory_id (str): ID of the memory to delete.
        """
    def delete_items(self, message_types: list[str], session_id: str, task_id: str, filters: dict = None):
        """Delete a memory by ID.
        Args:
            memory_id (str): ID of the memory to delete.
        """
        pass
